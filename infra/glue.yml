AWSTemplateFormatVersion: '2010-09-09'
Description: Configuraci칩n de AWS Glue usando LabRole. Cat치logo de datos, Crawler para zona RAW y Job ETL para zona PROCESSED.

Parameters:
  BaseStackName:
    Type: String
    Default: p2-s3-kinesis
    Description: Nombre del stack base que exporta el Bucket y el LabRole ARN.

Resources:

  # Aqui se define la base de datos en Glue donde se almacenar치n las tablas creadas por el Crawler, el crawler basicamente se encarga
  # de leer los datos en S3 y crear las tablas correspondientes en Glue.
  GlueDatabase:
    Type: AWS::Glue::Database
    Properties:
      CatalogId: !Ref "AWS::AccountId"
      DatabaseInput:
        Name: p5_data_lake_db
        Description: "Base de datos para el pipeline de eventos P5"

  # El crawler escanea los datos en S3 y crea/actualiza las tablas en la base de datos Glue. 
  # Este se encarga de escribir en la carpeta 'processed' los datos transformados.
  # La escritura en 'processed' se har치 en el script del job ETL.
  DataCrawler:
    Type: AWS::Glue::Crawler
    Properties:
      Name: p5-raw-data-crawler
      DatabaseName: !Ref GlueDatabase
      Role: 
        Fn::ImportValue: !Sub "${BaseStackName}-GlueServiceRoleArn"
      
      Targets:
        S3Targets:
          - Path: 
              Fn::Join:
                - ""
                - - "s3://"
                  - Fn::ImportValue: !Sub "${BaseStackName}-BucketName"
                  - "/raw/"
      
      # Definimos que hacer cuando se detectan cambios en el esquema de los datos y que se borren tablas obsoletas
      SchemaChangePolicy:
        UpdateBehavior: "UPDATE_IN_DATABASE"
        DeleteBehavior: "DEPRECATE_IN_DATABASE"
      
      # Aqui se define la frecuencia con la que el crawler escanea los datos en S3
      Schedule:
        ScheduleExpression: "cron(0/15 * * * ? *)" # En principio cada 15 minutos, se puede ajustar luego

  
  ETLJob:
    Type: AWS::Glue::Job
    Properties:
      Name: p5-transform-raw-to-parquet
      Description: "Job que transforma datos JSON a Parquet optimizado"
      Role: 
        Fn::ImportValue: !Sub "${BaseStackName}-GlueServiceRoleArn"
      Command:
        Name: glueetl
        ScriptLocation: 
          Fn::Join:
            - ""
            - - "s3://"
              - Fn::ImportValue: !Sub "${BaseStackName}-BucketName"
              - "/config/scripts/glue_job_script.py"
        PythonVersion: "3"
      
      GlueVersion: "4.0"
      WorkerType: G.1X
      NumberOfWorkers: 2
      
      DefaultArguments:
        "--job-bookmark-option": "job-bookmark-enable" # Procesa solo datos nuevos
        "--enable-metrics": "true"
        # Argumentos necesarios para el script de Python
        "--DATABASE_NAME": !Ref GlueDatabase
        "--OUTPUT_PATH": 
          Fn::Join:
            - ""
            - - "s3://"
              - Fn::ImportValue: !Sub "${BaseStackName}-BucketName"
              - "/processed/"

Outputs:
  CrawlerName:
    Value: !Ref DataCrawler
  JobName:
    Value: !Ref ETLJob